# Snakefile of the workflow of scRNAseq_Stanard_COSR_pipeline
#### import libraries #####
from snakemake.utils import min_version
import pandas as pd

#### setup report #####
# define the configfiles
configfile: 'config/test.yaml'
configfile: 'config/config.yaml'

# this is needed because the resources for RAM and cpus per rule are defined in the profile
configfile: "profiles/default/config.v8+.yaml"

# configfile: 'config/sample.yaml'

#### Load Sample Paths from CSV #####
# Load sample metadata
# df = pd.read_csv("config/samples.csv")
df = pd.read_csv(config["samples_csv"])
# Convert to dictionary
# I extract now, from the sample_path that I have in the df, which comes from the samples.csv from pypette only the folder of the samples. This is because in pypette samples.csv the sample_path is intended to locate the single fastq.gz files, while for cell ranger we need the 'folder' as Edoardo and Aurora have set.
# That's why I am introducing  the os.path.dirname
SAMPLES = {
    row.sample_id: {
        "link_rawImage": row.link_rawImage,
        "link_counts": row.link_counts,
        "hist_img": row.Histological_image,
        "species": row.specie_code,
        "RCTD_ref": row.Ref_dataset_RCTD
    }
    for row in df.itertuples(index=False)
}


#### load rules #####
# load the rules here because the variable SAMPLES needs to be available
# include the rules
include: 'rules/test.smk'
include: 'rules/preprocessing.smk'

#### Pipeline Main Rules #####
rule test_all:
    input:
        rules.test.output.test

# rule download_all:
#     '''
#     download the raw files per dataset
#     '''
#     input:
#         expand(rules.downloadData.output.counts_dir,
#         sample_id=SAMPLES.keys())

rule run_RCTD:
    '''
    generate the adata object per dataset
    '''
    input:
        expand(rules.runRCTD.output.csv_filters,
        sample_id=SAMPLES.keys())

rule run_mergeAdata:
    '''
    generate the adata object per dataset
    '''
    input:
        expand(rules.runAdataMerge.output.merged_adata,
        sample_id=SAMPLES.keys())

rule run_all:
    '''
    generate the adata object per dataset
    '''
    input:
        # expand(rules.generateAdata.output.adata,
        # sample_id=SAMPLES.keys()),
        # expand(rules.runStardist.output.pkl,
        # sample_id=SAMPLES.keys()),
        expand(rules.runBin2cell.output.nuclei_grouped_pkl,
        sample_id=SAMPLES.keys()),
        expand(rules.runBin2cell.output.nuclei_expanded_pkl,
        sample_id=SAMPLES.keys()),
        expand(rules.runBin2cell.output.nuclei_grouped_adata,
        sample_id=SAMPLES.keys()),
        expand(rules.runBin2cell.output.nuclei_expanded_adata,
        sample_id=SAMPLES.keys()),
        # expand(rules.runRCTD.output.csv_filters,
        # sample_id=SAMPLES.keys())